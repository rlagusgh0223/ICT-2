{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a399a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40382370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96dd4c10829d44ff8ee2ff4bf21c8d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4947b946b53b4da185120482390eaee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/465M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68dba606ef544608641758119bf8152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558ae7ad2498474389e5c53e8fd8befc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20102236ed824443a2a3da6875da9a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe202f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<mask>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마스크 토큰\n",
    "nlp.tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b9a9cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pizze is my <mask>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Pizze is my {nlp.tokenizer.mask_token}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ab6386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.47562044858932495,\n",
       "  'token': 2674,\n",
       "  'token_str': ' favorite',\n",
       "  'sequence': 'Pizze is my favorite food'},\n",
       " {'score': 0.17703180015087128,\n",
       "  'token': 5548,\n",
       "  'token_str': ' favourite',\n",
       "  'sequence': 'Pizze is my favourite food'},\n",
       " {'score': 0.17194382846355438,\n",
       "  'token': 5863,\n",
       "  'token_str': ' comfort',\n",
       "  'sequence': 'Pizze is my comfort food'},\n",
       " {'score': 0.022090883925557137,\n",
       "  'token': 3366,\n",
       "  'token_str': ' dream',\n",
       "  'sequence': 'Pizze is my dream food'},\n",
       " {'score': 0.017506703734397888,\n",
       "  'token': 6543,\n",
       "  'token_str': ' signature',\n",
       "  'sequence': 'Pizze is my signature food'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(f'Pizze is my {nlp.tokenizer.mask_token} food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be6450fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.07702243328094482,\n",
       "   'token': 122,\n",
       "   'token_str': ' now',\n",
       "   'sequence': '<s>Pizzs is now my<mask> food</s>'},\n",
       "  {'score': 0.059075310826301575,\n",
       "   'token': 460,\n",
       "   'token_str': ' always',\n",
       "   'sequence': '<s>Pizzs is always my<mask> food</s>'},\n",
       "  {'score': 0.048316530883312225,\n",
       "   'token': 2299,\n",
       "   'token_str': ' definitely',\n",
       "   'sequence': '<s>Pizzs is definitely my<mask> food</s>'},\n",
       "  {'score': 0.04578939080238342,\n",
       "   'token': 5072,\n",
       "   'token_str': ' basically',\n",
       "   'sequence': '<s>Pizzs is basically my<mask> food</s>'},\n",
       "  {'score': 0.04288775846362114,\n",
       "   'token': 1153,\n",
       "   'token_str': ' probably',\n",
       "   'sequence': '<s>Pizzs is probably my<mask> food</s>'}],\n",
       " [{'score': 0.4267764091491699,\n",
       "   'token': 2674,\n",
       "   'token_str': ' favorite',\n",
       "   'sequence': '<s>Pizzs is<mask> my favorite food</s>'},\n",
       "  {'score': 0.20855730772018433,\n",
       "   'token': 5548,\n",
       "   'token_str': ' favourite',\n",
       "   'sequence': '<s>Pizzs is<mask> my favourite food</s>'},\n",
       "  {'score': 0.1770884394645691,\n",
       "   'token': 5863,\n",
       "   'token_str': ' comfort',\n",
       "   'sequence': '<s>Pizzs is<mask> my comfort food</s>'},\n",
       "  {'score': 0.011815621517598629,\n",
       "   'token': 15163,\n",
       "   'token_str': ' junk',\n",
       "   'sequence': '<s>Pizzs is<mask> my junk food</s>'},\n",
       "  {'score': 0.011591872200369835,\n",
       "   'token': 7080,\n",
       "   'token_str': ' breakfast',\n",
       "   'sequence': '<s>Pizzs is<mask> my breakfast food</s>'}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(f\"Pizzs is {nlp.tokenizer.mask_token} my {nlp.tokenizer.mask_token} food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "027acf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForMaskedLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eebf483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(\"distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b97917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(\"distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0954ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "id2word = {i: word for word, i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "619e22eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pizza is my <mask> food.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = f\"Pizza is my {tokenizer.mask_token} food.\"\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a04855b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 9), dtype=int32, numpy=array([[    0,   510, 35280,    16,   127, 50264,   689,     4,     2]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(sequence, return_tensors='tf')\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "914aa9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50264"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f11de7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 9), dtype=int32, numpy=array([[    0,   510, 35280,    16,   127, 50264,   689,     4,     2]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "735e2424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=bool, numpy=array([False, False, False, False, False,  True, False, False, False])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0] == tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e011ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a06ee4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_indices = tf.where(input_ids[0] == tokenizer.mask_token_id)[0].numpy().tolist()\n",
    "mask_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e499d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5889bdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 9, 50265), dtype=float32, numpy=\n",
       "array([[[35.35766   , -3.8330357 , 18.556173  , ...,  3.12123   ,\n",
       "          5.922853  , 12.715132  ],\n",
       "        [ 1.9485795 , -5.0265136 , 14.836345  , ..., -1.1891124 ,\n",
       "          0.7311702 ,  0.7832576 ],\n",
       "        [ 2.0384846 , -4.953379  ,  5.4868183 , ..., -3.4435925 ,\n",
       "         -0.87940323, -0.41273394],\n",
       "        ...,\n",
       "        [-3.3596616 , -6.239405  ,  5.7364025 , ..., -1.9424853 ,\n",
       "         -1.668887  , -2.7464814 ],\n",
       "        [18.7403    , -5.234599  , 19.331993  , ...,  0.33183146,\n",
       "          2.8348486 ,  4.3758855 ],\n",
       "        [11.215204  , -5.8257084 , 28.299002  , ..., -0.9804349 ,\n",
       "         -3.4882178 ,  5.4295077 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = result[0]\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fabab6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = mask_token_indices[0]\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf55bfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 9, 50265])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa4677ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50265])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_logits = logits[0, i, :]\n",
    "mask_token_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce9db91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50265,), dtype=float32, numpy=\n",
       "array([-3.1226814 , -4.801013  ,  2.9825027 , ..., -4.36097   ,\n",
       "       -4.8979836 , -0.07158422], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e853a39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopKV2(values=<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([17.85983 , 16.52289 , 15.949996, 14.083212, 13.690206, 13.487871,\n",
       "       13.002301, 12.865288, 12.575063, 12.507711], dtype=float32)>, indices=<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
       "array([ 2674,  5863,  5548,  6543,  3366,  6813,  5440, 17771,  7080,\n",
       "        7476])>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상위 10개\n",
    "top = tf.math.top_k(mask_token_logits, k=10)\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc6ec01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ġfavorite\n",
      "Ġcomfort\n",
      "Ġfavourite\n",
      "Ġsignature\n",
      "Ġdream\n",
      "Ġpreferred\n",
      "Ġpassion\n",
      "Ġstaple\n",
      "Ġbreakfast\n",
      "Ġeveryday\n"
     ]
    }
   ],
   "source": [
    "for i in top.indices.numpy().tolist():\n",
    "    print(id2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "270e4f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pizza <mask> my <mask> food.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = f\"Pizza {tokenizer.mask_token} my {tokenizer.mask_token} food.\"\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31ad0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sequence, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22a4a310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
       "array([[3],\n",
       "       [5]], dtype=int64)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_indices = tf.where(input_ids[0] == tokenizer.mask_token_id)\n",
    "mask_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ad0debe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_indices = tf.squeeze(mask_token_indices).numpy().tolist()\n",
    "mask_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ea1bc62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 3 ====\n",
      "Ġis\n",
      "Ġwas\n",
      "Ġas\n",
      "Ġbecomes\n",
      "Ġequals\n",
      "Ġfor\n",
      "Ġdelivers\n",
      "Ġmakes\n",
      "Ġand\n",
      "Ġwith\n",
      "\n",
      "===== 5 ====\n",
      "Ġfavorite\n",
      "Ġcomfort\n",
      "Ġfavourite\n",
      "Ġjunk\n",
      "Ġbreakfast\n",
      "Ġlunch\n",
      "Ġown\n",
      "Ġsnack\n",
      "Ġfried\n",
      "Ġpreferred\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각 빈 칸의 가장 로짓(확률)이 높은 토큰들 출력\n",
    "result = model(input_ids)\n",
    "logits = result[0]\n",
    "for i in mask_token_indices:\n",
    "    print(f\"===== {i} ====\")\n",
    "    mask_token_logits = logits[0, i, :]\n",
    "    top = tf.math.top_k(mask_token_logits, k=10)\n",
    "    for i in top.indices.numpy().tolist():\n",
    "        print(id2word[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ccb95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa489ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1586322",
   "metadata": {},
   "source": [
    "# 1. 질문 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c670a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdace41702f408ca4ea8ed139729da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4382abe82134e15a4dc881f76b0be92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFDistilBertForQuestionAnswering were initialized from the model checkpoint at distilbert-base-cased-distilled-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfd99b57de2454a8601ef037159a76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96c6ba7309241739910f71427a6b12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af32d97be3104eb89f941c40240f3bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570b7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Seoul, officially the Seoul Special City, is the capital and largest metropolis of South Korea. \n",
    "Seoul has a population of 9.7 million people, and forms the heart of the Seoul Capital Area \n",
    "with the surrounding Incheon metropolis and Gyeonggi province.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78df8153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.862982988357544, 'start': 0, 'end': 5, 'answer': 'Seoul'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(question=\"where is the capital city of South Korea?\", context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2cbd788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9299280643463135,\n",
       " 'start': 123,\n",
       " 'end': 134,\n",
       " 'answer': '9.7 million'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(question=\"How many people live in Seoul?\", context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a336fb",
   "metadata": {},
   "source": [
    "# 2. NER(Named Entity Recognition)\n",
    "- 이름이 있는 존재를 알아본다.\n",
    "- 즉, 고유명사를 인식하게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36675207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db59863043cc403e998243415804dcd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bb4fed5587442a89edccef6949915e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing TFBertForTokenClassification: ['dropout_147']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4252a0d3ee9b4dbfb5379c2297a7bde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d0690c6e39490e8730885d4ac69c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ceb013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-LOC',\n",
       "  'score': 0.9995671,\n",
       "  'index': 1,\n",
       "  'word': 'Seoul',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9981558,\n",
       "  'index': 5,\n",
       "  'word': 'Seoul',\n",
       "  'start': 22,\n",
       "  'end': 27},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.97723025,\n",
       "  'index': 6,\n",
       "  'word': 'Special',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9895074,\n",
       "  'index': 7,\n",
       "  'word': 'City',\n",
       "  'start': 36,\n",
       "  'end': 40},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9969215,\n",
       "  'index': 17,\n",
       "  'word': 'South',\n",
       "  'start': 83,\n",
       "  'end': 88},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9992411,\n",
       "  'index': 18,\n",
       "  'word': 'Korea',\n",
       "  'start': 89,\n",
       "  'end': 94},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.999453,\n",
       "  'index': 20,\n",
       "  'word': 'Seoul',\n",
       "  'start': 97,\n",
       "  'end': 102},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.98211783,\n",
       "  'index': 37,\n",
       "  'word': 'Seoul',\n",
       "  'start': 170,\n",
       "  'end': 175},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9603082,\n",
       "  'index': 38,\n",
       "  'word': 'Capital',\n",
       "  'start': 176,\n",
       "  'end': 183},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9373542,\n",
       "  'index': 39,\n",
       "  'word': 'Area',\n",
       "  'start': 184,\n",
       "  'end': 188},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.998509,\n",
       "  'index': 43,\n",
       "  'word': 'Inc',\n",
       "  'start': 211,\n",
       "  'end': 214},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.97816354,\n",
       "  'index': 44,\n",
       "  'word': '##he',\n",
       "  'start': 214,\n",
       "  'end': 216},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9987452,\n",
       "  'index': 45,\n",
       "  'word': '##on',\n",
       "  'start': 216,\n",
       "  'end': 218},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99873143,\n",
       "  'index': 49,\n",
       "  'word': 'G',\n",
       "  'start': 234,\n",
       "  'end': 235},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.991698,\n",
       "  'index': 50,\n",
       "  'word': '##ye',\n",
       "  'start': 235,\n",
       "  'end': 237},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9972524,\n",
       "  'index': 51,\n",
       "  'word': '##ong',\n",
       "  'start': 237,\n",
       "  'end': 240},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99624276,\n",
       "  'index': 52,\n",
       "  'word': '##gi',\n",
       "  'start': 240,\n",
       "  'end': 242}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287579f",
   "metadata": {},
   "source": [
    "# 3. 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4df870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-small (https://huggingface.co/t5-small)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1cfc4d4e444ff4b93f4d2ed9fd82a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6650cb69d16d41b7b130afcfef1e6825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a183a1b8834d6f803f2d06968cf6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f146f0aa74bb4431a4937080bafe6512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summ = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9159d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "A zettelkasten consists of many individual notes with ideas and other short\n",
    "pieces of information that are taken down as they occur or are acquired. The\n",
    "notes are numbered hierarchically, so that new notes may be inserted at the\n",
    "appropriate place, and contain metadata to allow the note-taker to associate\n",
    "notes with each other. For example, notes may contain tags that describe key\n",
    "aspects of the note, and they may reference other notes. The numbering,\n",
    "by taking the notes down digitally and using appropriate knowledge management\n",
    "software. But it can be and has long been done on paper using index cards. The\n",
    "method not only allows a researcher to store and retrieve information related to\n",
    "their research, but also intends to enhance creativity. Cross-referencing notes\n",
    "through tags allows the researcher to perceive connections and relationships\n",
    "between individual items of information that may not be apparent in isolation.\n",
    "These emergent aspects of the method make the zettelkasten somewhat similar to a\n",
    "neural network with which one may \"converse\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2101229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'a zettelkasten consists of many individual notes with ideas and short pieces of information . notes may contain tags that describe key aspects of the note . cross-referencing notes through tags allows the researcher to perceive connections .'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ(text)    # 토큰개수 : 1천개 넘어가면 잘 안됨, 150개 미만이어도 잘 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db1e66",
   "metadata": {},
   "source": [
    "# 4. Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa32b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to roberta-large-mnli (https://huggingface.co/roberta-large-mnli)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7987ab241ee844c5b9d8c0c0590e81e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a7f6f27a6f44ca904155c7356fd781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at roberta-large-mnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2c3d045c49421fb11cb66c3c43465c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c29a64a63041969e581e45172a03f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba0b71b1b674f62bfaf6211c3fbc9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zs = pipeline('zero-shot-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8622b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"Pizza is my favorite food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d7d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['food', 'ocean', 'space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a081dd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Pizza is my favorite food',\n",
       " 'labels': ['food', 'space', 'ocean'],\n",
       " 'scores': [0.9870152473449707, 0.007221337873488665, 0.005763425957411528]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs(sequence, label)    # 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "631e7b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['politics', 'society', 'life']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "180b9ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Pizza is my favorite food',\n",
       " 'labels': ['life', 'society', 'politics'],\n",
       " 'scores': [0.5470685958862305, 0.3230592608451843, 0.12987221777439117]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs(sequence, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5e87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241d1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f7bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45259d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0771d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n",
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a64ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<mask>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마크스 토큰\n",
    "nlp.tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c3393c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pizza is my <mask>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Pizza is my {nlp.tokenizer.mask_token}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed7d36",
   "metadata": {},
   "source": [
    "# 1. 파이프라인에 문장을 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26cc68bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.07068394124507904,\n",
       "  'token': 2674,\n",
       "  'token_str': ' favorite',\n",
       "  'sequence': 'Pizza is my favorite'},\n",
       " {'score': 0.03550918772816658,\n",
       "  'token': 4592,\n",
       "  'token_str': ' lunch',\n",
       "  'sequence': 'Pizza is my lunch'},\n",
       " {'score': 0.03522925823926926,\n",
       "  'token': 8492,\n",
       "  'token_str': ' cake',\n",
       "  'sequence': 'Pizza is my cake'},\n",
       " {'score': 0.02607620321214199,\n",
       "  'token': 9366,\n",
       "  'token_str': ' pizza',\n",
       "  'sequence': 'Pizza is my pizza'},\n",
       " {'score': 0.025679104030132294,\n",
       "  'token': 17927,\n",
       "  'token_str': ' dessert',\n",
       "  'sequence': 'Pizza is my dessert'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(f'Pizza is my {nlp.tokenizer.mask_token}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcc9e15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.148834690451622,\n",
       "   'token': 2674,\n",
       "   'token_str': ' favorite',\n",
       "   'sequence': '<s>Pizza is my favorite my<mask> food.</s>'},\n",
       "  {'score': 0.06916295737028122,\n",
       "   'token': 8,\n",
       "   'token_str': ' and',\n",
       "   'sequence': '<s>Pizza is my and my<mask> food.</s>'},\n",
       "  {'score': 0.036127083003520966,\n",
       "   'token': 1441,\n",
       "   'token_str': ' friend',\n",
       "   'sequence': '<s>Pizza is my friend my<mask> food.</s>'},\n",
       "  {'score': 0.01511524710804224,\n",
       "   'token': 3795,\n",
       "   'token_str': ' mom',\n",
       "   'sequence': '<s>Pizza is my mom my<mask> food.</s>'},\n",
       "  {'score': 0.014074320904910564,\n",
       "   'token': 5548,\n",
       "   'token_str': ' favourite',\n",
       "   'sequence': '<s>Pizza is my favourite my<mask> food.</s>'}],\n",
       " [{'score': 0.7035160660743713,\n",
       "   'token': 2674,\n",
       "   'token_str': ' favorite',\n",
       "   'sequence': '<s>Pizza is my<mask> my favorite food.</s>'},\n",
       "  {'score': 0.12073897570371628,\n",
       "   'token': 5548,\n",
       "   'token_str': ' favourite',\n",
       "   'sequence': '<s>Pizza is my<mask> my favourite food.</s>'},\n",
       "  {'score': 0.07828744500875473,\n",
       "   'token': 5863,\n",
       "   'token_str': ' comfort',\n",
       "   'sequence': '<s>Pizza is my<mask> my comfort food.</s>'},\n",
       "  {'score': 0.00911870226264,\n",
       "   'token': 3366,\n",
       "   'token_str': ' dream',\n",
       "   'sequence': '<s>Pizza is my<mask> my dream food.</s>'},\n",
       "  {'score': 0.006468731444329023,\n",
       "   'token': 6543,\n",
       "   'token_str': ' signature',\n",
       "   'sequence': '<s>Pizza is my<mask> my signature food.</s>'}]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(f'Pizza is my {nlp.tokenizer.mask_token} my {nlp.tokenizer.mask_token} food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d590cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForMaskedLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02fe8ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(\"distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "555a0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "id2word = {i: word for word, i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8fd8563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pizza is my <mask> food.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = f\"Pizza is my {tokenizer.mask_token} food.\"\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "777231c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 9), dtype=int32, numpy=array([[    0,   510, 35280,    16,   127, 50264,   689,     4,     2]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(sequence, return_tensors=\"tf\")\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ce8c035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50264"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b817a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=bool, numpy=array([False, False, False, False, False,  True, False, False, False])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0] == tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "268ca9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6224cf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[5]], dtype=int64)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.where(input_ids[0] == tokenizer.mask_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7e7e16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_indices = tf.where(input_ids[0] == tokenizer.mask_token_id)[0].numpy().tolist()\n",
    "mask_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ebeecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9a37584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 9, 50265), dtype=float32, numpy=\n",
       "array([[[35.35766   , -3.8330357 , 18.556173  , ...,  3.12123   ,\n",
       "          5.922853  , 12.715132  ],\n",
       "        [ 1.9485795 , -5.0265136 , 14.836345  , ..., -1.1891124 ,\n",
       "          0.7311702 ,  0.7832576 ],\n",
       "        [ 2.0384846 , -4.953379  ,  5.4868183 , ..., -3.4435925 ,\n",
       "         -0.87940323, -0.41273394],\n",
       "        ...,\n",
       "        [-3.3596616 , -6.239405  ,  5.7364025 , ..., -1.9424853 ,\n",
       "         -1.668887  , -2.7464814 ],\n",
       "        [18.7403    , -5.234599  , 19.331993  , ...,  0.33183146,\n",
       "          2.8348486 ,  4.3758855 ],\n",
       "        [11.215204  , -5.8257084 , 28.299002  , ..., -0.9804349 ,\n",
       "         -3.4882178 ,  5.4295077 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = result[0]\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71954b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = mask_token_indices[0]\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "558151b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 9, 50265])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9757b67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50265])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_logits = logits[0, i, :]\n",
    "mask_token_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ce657e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50265,), dtype=float32, numpy=\n",
       "array([-3.1226814 , -4.801013  ,  2.9825027 , ..., -4.36097   ,\n",
       "       -4.8979836 , -0.07158422], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51c5417f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopKV2(values=<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([17.85983 , 16.52289 , 15.949996, 14.083212, 13.690206, 13.487871,\n",
       "       13.002301, 12.865288, 12.575063, 12.507711], dtype=float32)>, indices=<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
       "array([ 2674,  5863,  5548,  6543,  3366,  6813,  5440, 17771,  7080,\n",
       "        7476])>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = tf.math.top_k(mask_token_logits, k=10)\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6da66ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ġfavorite\n",
      "Ġcomfort\n",
      "Ġfavourite\n",
      "Ġsignature\n",
      "Ġdream\n",
      "Ġpreferred\n",
      "Ġpassion\n",
      "Ġstaple\n",
      "Ġbreakfast\n",
      "Ġeveryday\n"
     ]
    }
   ],
   "source": [
    "for i in top.indices.numpy().tolist():\n",
    "    print(id2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12685996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pizza <mask> my <mask> food.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = f\"Pizza {tokenizer.mask_token} my {tokenizer.mask_token} food.\"\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20eb3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sequence, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1382da8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
       "array([[3],\n",
       "       [5]], dtype=int64)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_indices = tf.where(input_ids[0] == tokenizer.mask_token_id)\n",
    "mask_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18fcdbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_indices = tf.squeeze(mask_token_indices).numpy().tolist()\n",
    "mask_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afc11aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(input_ids)\n",
    "logits = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0cb307d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 3 ===\n",
      "Ġis\n",
      "Ġwas\n",
      "Ġas\n",
      "Ġbecomes\n",
      "Ġequals\n",
      "Ġfor\n",
      "Ġdelivers\n",
      "Ġmakes\n",
      "Ġand\n",
      "Ġwith\n",
      "=== 5 ===\n",
      "Ġfavorite\n",
      "Ġcomfort\n",
      "Ġfavourite\n",
      "Ġjunk\n",
      "Ġbreakfast\n",
      "Ġlunch\n",
      "Ġown\n",
      "Ġsnack\n",
      "Ġfried\n",
      "Ġpreferred\n"
     ]
    }
   ],
   "source": [
    "for i in mask_token_indices:\n",
    "    print(f\"=== {i} ===\")\n",
    "    mask_token_logits = logits[0, i, :]\n",
    "    top = tf.math.top_k(mask_token_logits, k=10)\n",
    "    for i in top.indices.numpy().tolist():\n",
    "        print(id2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481eabed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
